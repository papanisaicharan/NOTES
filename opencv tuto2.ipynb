{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#https://matplotlib.org/users/image_tutorial.html  visit this link for more about plotting using matplot\n",
    "\n",
    "Apart from OpenCV, Python also provides a module time which is helpful in measuring the time of execution. Another module profile helps to get detailed report on the code, like how much time each function in the code took, how many times the function was called etc. But, if you are using IPython, all these features are integrated in an user-friendly manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "trying the image tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Measuring Performance with OpenCV\n",
    "\n",
    "cv2.getTickCount function returns the number of clock-cycles after a reference event (like the moment machine was switched ON) to the moment this function is called. So if you call it before and after the function execution, you get number of clock-cycles used to execute a function.\n",
    "\n",
    "cv2.getTickFrequency function returns the frequency of clock-cycles, or the number of clock-cycles per second. So to find the time of execution in seconds, you can do following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saicharan\n",
      "0.00022753\n"
     ]
    }
   ],
   "source": [
    "e1 = cv2.getTickCount()\n",
    "# your code execution\n",
    "print(\"saicharan\")\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000181318\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('images/imge1.jpg')\n",
    "\n",
    "e1 = cv2.getTickCount()\n",
    "for i in range(5,49,2):\n",
    "    img1 = cv2.medianBlur(img1,i)\n",
    "e2 = cv2.getTickCount()\n",
    "t = (e2 - e1)/cv2.getTickFrequency()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Default Optimization in OpenCV\n",
    "\n",
    "Many of the OpenCV functions are optimized using SSE2, AVX etc. It contains unoptimized code also. So if our system support these features, we should exploit them (almost all modern day processors support them). It is enabled by default while compiling. So OpenCV runs the optimized code if it is enabled, else it runs the unoptimized code. You can use cv2.useOptimized() to check if it is enabled/disabled and cv2.setUseOptimized() to enable/disable it. Let’s see a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.useOptimized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324 ns ± 10.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit res = cv2.medianBlur(img1,49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "cv2.setUseOptimized(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.useOptimized()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334 ns ± 17.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit res = cv2.medianBlur(img1,49)\n",
    "#compared to above it is less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 ns ± 35.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "x = 5\n",
    "%timeit y=x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.8 ns ± 7.38 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y=x*x\n",
    "#it got drastically varied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 ns ± 50.3 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "z = np.uint8([5])\n",
    "%timeit y=z*z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 ns ± 53.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y=np.square(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note : Python scalar operations are faster than Numpy scalar operations. So for operations including one or two elements, Python scalar is better than Numpy arrays. Numpy takes advantage when size of array is a little bit bigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270 ns ± 25.5 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit z = cv2.countNonZero(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797 ns ± 96.4 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit z = np.count_nonzero(img1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Normally, OpenCV functions are faster than Numpy functions. So for same operation, OpenCV functions are preferred. But, there can be exceptions, especially when Numpy works with views instead of copies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Performance Optimization Techniques\n",
    "\n",
    "There are several techniques and coding methods to exploit maximum performance of Python and Numpy. Only relevant ones are noted here and links are given to important sources. The main thing to be noted here is that, first try to implement the algorithm in a simple manner. Once it is working, profile it, find the bottlenecks and optimize them.\n",
    "\n",
    "Avoid using loops in Python as far as possible, especially double/triple loops etc. They are inherently slow.\n",
    "Vectorize the algorithm/code to the maximum possible extent because Numpy and OpenCV are optimized for vector operations.\n",
    "Exploit the cache coherence.\n",
    "Never make copies of array unless it is needed. Try to use views instead. Array copying is a costly operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Additional Resources\n",
    "\n",
    "Python Optimization Techniques : https://wiki.python.org/moin/PythonSpeed/PerformanceTips\n",
    "Scipy Lecture Notes - Advanced Numpy : http://scipy-lectures.github.io/advanced/advanced_numpy/index.html#advanced-numpy\n",
    "Timing and Profiling in IPython : http://pynash.org/2013/03/06/timing-and-profiling.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Overview: Optimize what needs optimizing\n",
    "\n",
    "You can only know what makes your program slow after first getting the program to give correct results, then running it to see if the correct program is slow. When found to be slow, profiling can show what parts of the program are consuming most of the time. A comprehensive but quick-to-run test suite can then ensure that future optimizations don't change the correctness of your program. In short:\n",
    "\n",
    "Get it right.\n",
    "Test it's right.\n",
    "Profile if slow.\n",
    "Optimise.\n",
    "Repeat from 2.\n",
    "Certain optimizations amount to good programming style and so should be learned as you learn the language. An example would be moving the calculation of values that don't change within a loop, outside of the loop.\n",
    "### Choose the Right Data Structure\n",
    "### Sorting\n",
    "Sorting lists of basic Python objects is generally pretty efficient. The sort method for lists takes an optional comparison function as an argument that can be used to change the sorting behavior. This is quite convenient, though it can significantly slow down your sorts, as the comparison function will be called many times. In Python 2.4, you should use the key argument to the built-in sort instead, which should be the fastest way to sort.\n",
    "\n",
    "Only if you are using older versions of Python (before 2.4) does the following advice from Guido van Rossum apply:\n",
    "\n",
    "An alternative way to speed up sorts is to construct a list of tuples whose first element is a sort key that will sort properly using the default comparison, and whose second element is the original list element. This is the so-called Schwartzian Transform, also known as DecorateSortUndecorate (DSU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def sortBy(somelist,n):\n",
    "    nlist = [(x[n],x) for x in somelist]\n",
    "    nlist.sort()\n",
    "    return [val for (key,val) in nlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "def sortby_inplace(somelist, n):\n",
    "    somelist[:] = [(x[n], x) for x in somelist]\n",
    "    somelist.sort()\n",
    "    somelist[:] = [val for (key, val) in somelist]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "somelist = [(1, 2, 'def'), (3, 6, 'abc'), (2, -4, 'ghi')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 'def'), (2, -4, 'ghi'), (3, 6, 'abc')]"
      ]
     },
     "execution_count": 28,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somelist.sort()\n",
    "somelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 6, 'abc'), (1, 2, 'def'), (2, -4, 'ghi')]\n",
      "0.000143997\n"
     ]
    }
   ],
   "source": [
    "\n",
    "e1 = cv2.getTickCount()\n",
    "nlist = sortBy(somelist, 2)\n",
    "print(nlist)\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 6, 'abc'), (1, 2, 'def'), (2, -4, 'ghi')]\n",
      "0.000146918\n"
     ]
    }
   ],
   "source": [
    "e1 = cv2.getTickCount()\n",
    "nlist1 = sortby_inplace(somelist, 2)\n",
    "print(somelist)\n",
    "e2 = cv2.getTickCount()\n",
    "time = (e2 - e1)/ cv2.getTickFrequency()\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "somelist == nlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\"change all the 'a's to 'b's\" in any given string. Instead, you have to create a new string with the desired properties. This continual copying can lead to significant inefficiencies in Python programs.\n",
    "\n",
    "avoid like this:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saicharan\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "list1 = \"saicharan\"\n",
    "for substring in list1:\n",
    "    s += substring\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saicharan\n"
     ]
    }
   ],
   "source": [
    "#use like this for optimization\n",
    "s = \"\".join(list1)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saicharan'"
      ]
     },
     "execution_count": 72,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"\"\n",
    "for x in list1:\n",
    "    s += str(x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saicharan'"
      ]
     },
     "execution_count": 77,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use like this\n",
    "slist = [str(elt) for elt in list1]\n",
    "s = \"\".join(slist)\n",
    "s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "out = \"<html>\" + head + prologue + query + tail + \"</html>\"\n",
    "#Instead, use\n",
    "\n",
    "out = \"<html>%s%s%s%s</html>\" % (head, prologue, query, tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If the body of your loop is simple, the interpreter overhead of the for loop itself can be a substantial amount of the overhead. This is where the map function is handy. You can think of map as a for moved into C code. The only restriction is that the \"loop body\" of map must be a function call. Besides the syntactic benefit of list comprehensions, they are often as fast or faster than equivalent use of map.\n",
    "\n",
    "Here's a straightforward example. Instead of looping over a list of words and converting them to upper case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAICHARAN\n"
     ]
    }
   ],
   "source": [
    "newlist = []\n",
    "for word in list1:\n",
    "    newlist.append(word.upper())\n",
    "print(\"\".join(newlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "you can use map to push the loop from the interpreter into compiled C code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAICHARAN\n"
     ]
    }
   ],
   "source": [
    "newlist = map(str.upper, list1)\n",
    "print(\"\".join(newlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "List comprehensions were added to Python in version 2.0 as well. They provide a syntactically more compact and more efficient way of writing the above for loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAICHARAN\n"
     ]
    }
   ],
   "source": [
    "newlist = [s.upper() for s in list1]\n",
    "print(\"\".join(newlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "#see we have drastically got down the execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Generator expressions were added to Python in version 2.4. They function more-or-less like list comprehensions or map but avoid the overhead of generating the entire list at once. Instead, they return a generator object which can be iterated over bit-by-bit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAICHARAN\n"
     ]
    }
   ],
   "source": [
    "iterator = (s.upper() for s in list1)\n",
    "print(\"\".join(newlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu Linux)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}